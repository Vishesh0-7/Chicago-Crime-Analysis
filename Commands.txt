Instructions for Running the MapReduce WordCount Job

1. Set Up Hadoop and Java
Ensure Hadoop is installed and running in pseudo-distributed or fully distributed mode and also Install Java, and set all the environment variables.

2. Start Hadoop Cluster
If Starting for the first time format the Namenode using:

hdfs namenode -format

Start the Hadoop Distributed File System (HDFS) and YARN by running the following commands in your command prompt(administrator):

start-dfs.sh
start-yarn.sh

Run the jps Command to see if the Namenode, Datanode, NodeManagers and the ResourceManager are active.

3. Create Input Directory in HDFS
Create a directory in HDFS where the input file will be stored:

hdfs dfs -mkdir /input

4. Add the Input File to HDFS
Copy the `Input.txt` file from your local machine to the input directory in HDFS:

hdfs dfs -put C:\Users\vishe\Documents\Files\Crimes_data.csv /input

Be Sure to put the right path above and then run the command.

5. Run the MapReduce Jobs
Execute the MapReduce jobs by specifying the input directory and the output directory, and change the path to where your Jar file is stored.

hadoop jar ChicagoCrimeAnalysis.jar com.mapreduce.cca.ChicagoCrimeAnalysis /input/Crime_Data.csv /Output1/job1 /Output1/job2 /Output1/job3


6. Check the Output Files
After the job completes, list the contents of the output directory to verify the presence of the `part-r-00000` file, which contains the word count results:

hadoop fs -ls /Output/job1

7. Download the Output
Copy the result file from HDFS to your local file system:

hadoop dfs -get /Output/job1/part-r-00000 C:\Users\vishe\Documents\Files\job1.txt

similarly do for job2 and job3

Change the path to wherever you want to store the output file

8. View the Output
Open the `Output.txt` file to see the word counts:

hadoop dfs -cat /Output/job1/*

9. Stop the Hadoop Cluster
After completing the job, stop the Hadoop services:

stop-yarn.cmd
stop-dfs.cmd

Thank You..
By Vishesh Raju
